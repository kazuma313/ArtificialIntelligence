{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648, 1152, 3)\n"
     ]
    }
   ],
   "source": [
    "image = face_recognition.load_image_file(\"foto.JPG\")\n",
    "print(image.shape)\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(204, 491, 247, 448),\n",
       " (257, 919, 308, 867),\n",
       " (233, 765, 276, 722),\n",
       " (198, 163, 260, 100),\n",
       " (218, 601, 254, 565),\n",
       " (223, 847, 266, 804),\n",
       " (205, 337, 257, 285),\n",
       " (170, 733, 206, 697),\n",
       " (250, 1057, 286, 1021)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"foto.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_locations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mComputerVision\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFaceRecognation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mResources\u001b[39m\u001b[38;5;130;01m\\b\u001b[39;00m\u001b[38;5;124mackground.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (top, right, bottom, left) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mface_locations\u001b[49m:\n\u001b[0;32m      3\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(image, (left, top), (right, bottom), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m, image) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'face_locations' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for (top, right, bottom, left) in face_locations:\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    " \n",
    "cv2.imshow(\"image\", image) \n",
    "  \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mComputerVision\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFaceRecognation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mResources\u001b[39m\u001b[38;5;130;01m\\b\u001b[39;00m\u001b[38;5;124mackground.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      4\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m) \n\u001b[0;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows() \n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(139, 448, 325, 262)]\n",
      "[(139, 469, 325, 283)]\n",
      "[(139, 469, 325, 283)]\n",
      "[(139, 469, 325, 283)]\n",
      "[(139, 448, 325, 262)]\n",
      "[(139, 448, 325, 262)]\n",
      "[(167, 442, 322, 287)]\n",
      "[(167, 442, 322, 287)]\n",
      "[(184, 442, 339, 287)]\n",
      "[(196, 411, 325, 282)]\n",
      "[(196, 411, 325, 282)]\n",
      "[(196, 411, 325, 282)]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[(184, 408, 339, 253)]\n",
      "[(160, 428, 345, 242)]\n",
      "[(160, 428, 345, 242)]\n",
      "[(160, 448, 345, 262)]\n",
      "[(160, 448, 345, 262)]\n",
      "[(160, 448, 345, 262)]\n",
      "[(139, 448, 325, 262)]\n",
      "[(139, 448, 325, 262)]\n",
      "[(160, 448, 345, 262)]\n",
      "[(160, 448, 345, 262)]\n",
      "[(160, 428, 345, 242)]\n",
      "[(139, 428, 325, 242)]\n",
      "[(139, 428, 325, 242)]\n",
      "[(139, 428, 325, 242)]\n",
      "[(139, 428, 325, 242)]\n",
      "[(118, 428, 304, 242)]\n",
      "[(118, 428, 304, 242)]\n",
      "[(118, 428, 304, 242)]\n",
      "[(118, 428, 304, 242)]\n",
      "[(118, 428, 304, 242)]\n",
      "[(118, 428, 304, 242)]\n",
      "[(118, 428, 304, 242)]\n",
      "[(118, 428, 304, 242)]\n",
      "[(118, 448, 304, 262)]\n",
      "[(118, 448, 304, 262)]\n",
      "[(118, 448, 304, 262)]\n",
      "[(118, 448, 304, 262)]\n",
      "[(118, 448, 304, 262)]\n",
      "[(118, 448, 304, 262)]\n",
      "[(118, 448, 304, 262)]\n",
      "[(118, 448, 304, 262)]\n",
      "[(139, 448, 325, 262)]\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(3, 512)\n",
    "capture.set(4, 512)\n",
    "\n",
    "while (capture.isOpened()):\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    print(face_locations)\n",
    "    if ret == True:\n",
    "\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        if cv2.waitKey(25) in (ord('q'), ord('Q')):\n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "    \n",
    "    cv2.imshow('Frame', frame) \n",
    "\n",
    "capture.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From video tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r\".\\Resources\\background.png\")\n",
    "cv2.imshow(\"image\", image) \n",
    "  \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading encoded file\n",
      "encoded file collected\n"
     ]
    }
   ],
   "source": [
    "img_background =  cv2.imread(r\".\\Resources\\background.png\")\n",
    "img_background = cv2.resize(img_background, (1280, 512), fx=1, fy=1)\n",
    "\n",
    "folder_mode_path = r\".\\Resources\\Modes\"\n",
    "mode_path_list = os.listdir(folder_mode_path)\n",
    "img_mode_list = []\n",
    "\n",
    "print(\"loading encoded file\")\n",
    "file_encode = open(r\".\\model\\Encode\\my_EncodeFile.p\", \"rb\")\n",
    "encodeListKnown = pickle.load(file_encode)\n",
    "file_encode.close()\n",
    "encoded_img_list, id_list = encodeListKnown\n",
    "\n",
    "print(\"encoded file collected\")\n",
    "\n",
    "# get images mode and resize them\n",
    "for path in mode_path_list:\n",
    "    img_mode = cv2.imread(os.path.join(folder_mode_path, path))\n",
    "    img_mode = cv2.resize(img_mode, (430, 480), fx=1, fy=1)\n",
    "    img_mode_list.append(img_mode)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 128)\n",
    "cap.set(4, 128)\n",
    "\n",
    "while True:\n",
    "    succes, img = cap.read()\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    encode_frames = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "    \n",
    "    \n",
    "    for encode_frame, face_loc in zip(encode_frames, face_locations):\n",
    "        # check the matches face encoded\n",
    "        matches = face_recognition.compare_faces(encoded_img_list, encode_frame)\n",
    "        # magnitude of the distance similarity\n",
    "        face_distance = face_recognition.face_distance(encoded_img_list, encode_frame)\n",
    "        \n",
    "        best_match_index = np.argmin(face_distance)\n",
    "        if matches[best_match_index]:\n",
    "            person_id = id_list[best_match_index]\n",
    "            \n",
    "            # cvzone.putTextRect(\n",
    "            #         img, f\"Face Detected, person id : {person_id[0]}\", (20, 100),\n",
    "            #         scale=1, thickness=1, \n",
    "            #         colorT=(0, 0, 255), colorR=(255, 100, 0), \n",
    "            #         font=cv2.FONT_HERSHEY_PLAIN, \n",
    "            #         offset=1,  \n",
    "            #         border=1, colorB=(0, 5, 0)\n",
    "            #     )\n",
    "\n",
    "        \n",
    "            for top, right, bottom, left in face_locations:\n",
    "                # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "                top -= 60\n",
    "                right += 20\n",
    "                bottom += 60\n",
    "                left -= 20\n",
    "                # Draw a box around the face\n",
    "                cv2.rectangle(img, \n",
    "                              (left, top), \n",
    "                              (right, bottom), \n",
    "                              (0, 0, 255), \n",
    "                              2)\n",
    "\n",
    "                # Draw a label with a name below the face\n",
    "                cv2.rectangle(img, \n",
    "                              (left, bottom - 35), \n",
    "                              (right, bottom), \n",
    "                              (0, 0, 255), \n",
    "                              cv2.FILLED)\n",
    "                \n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(img, f\" {person_id[0]}: {person_id[1]}\", (left + 2, bottom - 2), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "\n",
    "    img_background[100:100+360, 50:50+640, :] = img\n",
    "    img_background[20:20+480, 800:800+430, :] = img_mode_list[3]    \n",
    "    \n",
    "    cv2.imshow(\"image Background\", img_background)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recognation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
